import os
import io
import base64
import re
from concurrent.futures import ThreadPoolExecutor, as_completed

import streamlit as st
from openai import OpenAI
from dotenv import load_dotenv

from PIL import Image
import numpy as np  # â† ì¶”ê°€

# imageioê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì€ í™˜ê²½ì—ì„œë„ ì•±ì´ ì£½ì§€ ì•Šê²Œ ì˜ˆì™¸ ì²˜ë¦¬
try:
    import imageio.v2 as imageio
except ImportError:
    imageio = None

# =========================
# .env ë¡œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ (ë¡œì»¬ ê°œë°œìš©)
# =========================
load_dotenv()

# =========================
# í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • & ìŠ¤íƒ€ì¼
# =========================
st.set_page_config(
    page_title="imageking",
    page_icon="ğŸ¬",
    layout="wide",
)

st.markdown(
    """
    <style>
    textarea {
        font-size: 0.9rem !important;
        line-height: 1.4 !important;
    }
    .main-title {
        font-size: 2.3rem;
        font-weight: 800;
        margin-bottom: 0.2rem;
    }
    .main-subtitle {
        font-size: 0.95rem;
        color: #555;
        margin-bottom: 1.5rem;
    }
    .logo-badge {
        display: inline-flex;
        align-items: center;
        gap: 0.35rem;
        padding: 0.25rem 0.6rem;
        border-radius: 999px;
        background: #F3F4FF;
        color: #444;
        font-size: 0.8rem;
        margin-bottom: 0.5rem;
    }
    .logo-badge span.emoji {
        font-size: 1rem;
    }
    /* ê²°ê³¼ í…Œì´ë¸”ìš© ìŠ¤í¬ë¡¤ ë°•ìŠ¤ */
    .results-container {
        max-height: 600px;
        overflow-y: auto;
        padding-right: 8px;
        border-radius: 8px;
        border: 1px solid #eee;
        background-color: #fafafa;
    }
    /* í…Œì´ë¸” ì•ˆ í…ìŠ¤íŠ¸ í¬ê¸° ì¤„ì´ê¸° */
    .small-text-cell {
        font-size: 0.8rem;
        line-height: 1.3;
    }
    </style>
    """,
    unsafe_allow_html=True,
)

# =========================
# í™˜ê²½ë³€ìˆ˜ ê°€ì ¸ì˜¤ê¸°
# =========================
def get_env(key: str, default: str = "") -> str:
    value = os.getenv(key)
    return value if value is not None else default


GPT_API_KEY = get_env("GPT_API_KEY", "")

if not GPT_API_KEY:
    st.error("âŒ GPT_API_KEY ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. .env ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

client = OpenAI(api_key=GPT_API_KEY)

# =========================
# ì´ë¯¸ì§€ / ì˜ìƒ ëª¨ë¸ í”„ë¦¬ì…‹
# =========================
IMAGE_MODELS = {
    "OpenAI gpt-image-1": "gpt-image-1",
}

VIDEO_MODELS = {
    "ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ â†’ MP4 (ë¡œì»¬ í•©ì„±)": "local_sequence_mp4",
}

# =========================
# ìŠ¤íƒ€ì¼ í”„ë¦¬ì…‹ ì •ì˜
# =========================
STYLE_PRESETS = {
    "ë‹¤í + ì‚¬ì‹¤ì  ë°°ê²½": (
        "Style Wrapper:\n"
        "Background: documentary-style, semi-realistic environment, neutral color grading, "
        "soft cinematic lighting, subtle film grain.\n"
        "Characters: realistic human figures or crowds that match the story context.\n"
        "Camera: wide cinematic framing with natural depth and gentle atmospheric haze.\n"
    ),
    "ë‹¤í + ìŠ¤í‹±ë§¨ ì„¤ëª… ìºë¦­í„°": (
        "Style Wrapper:\n"
        "Background: semi-realistic cinematic environment, dramatic lighting, soft shadows, mild film grain, "
        "dystopian or documentary atmosphere.\n"
        "Characters: simple 2D stickman drawn with thick black outlines, white circular face, small black-dot eyes, "
        "line-based limbs, cartoon-like contrast against the realistic background.\n"
        "Camera: wide cinematic framing, slight depth of field, subtle atmospheric haze.\n"
    ),
    "í’€ 2D ì• ë‹ˆë©”ì´ì…˜": (
        "Style Wrapper:\n"
        "Background: flat 2D animation style, pastel colors, simple geometric buildings and props.\n"
        "Characters: cute 2D stickman-style characters with thick black outlines and expressive poses.\n"
        "Camera: simple animation-style wide shot, clean composition, no film grain.\n"
    ),
}

# =========================
# ì„¸ì…˜ ìƒíƒœ ê¸°ë³¸ê°’
# =========================
st.session_state.setdefault("scenes", [])
st.session_state.setdefault("raw_script", "")

st.session_state.setdefault("style_preset", "ë‹¤í + ìŠ¤í‹±ë§¨ ì„¤ëª… ìºë¦­í„°")
st.session_state.setdefault("lock_character", True)

st.session_state.setdefault("image_model_label", "OpenAI gpt-image-1")
st.session_state.setdefault("image_orientation", "ì •ì‚¬ê°í˜• 1:1 (1024x1024)")
st.session_state.setdefault("image_quality", "low")

st.session_state.setdefault("video_model_label", "ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ â†’ MP4 (ë¡œì»¬ í•©ì„±)")
st.session_state.setdefault("seconds_per_scene", 3.0)
st.session_state.setdefault("video_bytes", None)
st.session_state.setdefault("video_error_msg", None)

# =========================
# ìœ í‹¸ í•¨ìˆ˜ë“¤
# =========================
def parse_script(text: str):
    """
    1
    í•œêµ­ì–´ë¬¸ì¥â€¦
    Shot on ...
    2
    ...
    ì´ëŸ° í˜•ì‹ì˜ í…ìŠ¤íŠ¸ë¥¼ scenes ë¦¬ìŠ¤íŠ¸ë¡œ íŒŒì‹±
    """
    scenes = []
    pattern = r'(\d+)\s*\n(.+?)(?=\n\d+\s*\n|\Z)'
    matches = re.findall(pattern, text, flags=re.DOTALL)

    for num, block in matches:
        block = block.strip()
        block = block.replace("\u2028", "\n")  # íŠ¹ìˆ˜ ì¤„ë°”ê¿ˆ ì¹˜í™˜

        if "Shot on" in block:
            ko_part, en_part = block.split("Shot on", 1)
            korean = ko_part.strip()
            english_prompt = "Shot on" + en_part.strip()
        else:
            korean = block.strip()
            english_prompt = ""

        scenes.append(
            {
                "id": int(num),
                "korean": korean,
                "prompt_en": english_prompt,
                "image_b64": None,
            }
        )
    return scenes


def get_image_params():
    orientation = st.session_state.get("image_orientation", "ì •ì‚¬ê°í˜• 1:1 (1024x1024)")
    quality = st.session_state.get("image_quality", "low")

    if orientation.startswith("ì •ì‚¬ê°í˜•"):
        size = "1024x1024"
    elif orientation.startswith("ê°€ë¡œí˜•"):
        size = "1536x1024"
    else:
        size = "1024x1536"

    return size, quality


def build_full_prompt(base_prompt: str) -> str:
    style_name = st.session_state.get("style_preset", "ë‹¤í + ìŠ¤í‹±ë§¨ ì„¤ëª… ìºë¦­í„°")
    style_wrapper = STYLE_PRESETS.get(style_name, "")

    lock_char = st.session_state.get("lock_character", False)
    if lock_char:
        style_wrapper += (
            "\nThe main character is a recurring simple 2D stickman narrator with a white circular face "
            "and small black-dot eyes, always present somewhere in the scene, explaining or reacting to the situation.\n"
        )

    if style_wrapper:
        return style_wrapper + "\nScene:\n" + base_prompt
    else:
        return base_prompt


def generate_image(prompt: str):
    if not prompt:
        return None

    size, quality = get_image_params()
    full_prompt = build_full_prompt(prompt)

    image_model_label = st.session_state.get("image_model_label", "OpenAI gpt-image-1")
    model = IMAGE_MODELS.get(image_model_label, "gpt-image-1")

    resp = client.images.generate(
        model=model,
        prompt=full_prompt,
        size=size,
        quality=quality,
        n=1,
    )
    return resp.data[0].b64_json


def bulk_generate_images(scenes, max_workers: int = 4):
    def _task(idx):
        prompt = scenes[idx]["prompt_en"]
        b64 = generate_image(prompt)
        return idx, b64

    with ThreadPoolExecutor(max_workers=max_workers) as ex:
        futures = [ex.submit(_task, i) for i in range(len(scenes))]
        for fut in as_completed(futures):
            idx, b64 = fut.result()
            scenes[idx]["image_b64"] = b64


def b64_to_bytes(b64_str: str):
    return base64.b64decode(b64_str)


def create_video_from_scenes(
    scenes,
    seconds_per_scene: float,
    fps: int = 30,
) -> tuple[bytes | None, str | None]:
    """
    ì„±ê³µ ì‹œ (video_bytes, None)
    ì‹¤íŒ¨ ì‹œ (None, ì—ëŸ¬ë©”ì‹œì§€)
    """
    if imageio is None:
        return None, "IMAGEIO_MISSING"

    images = []
    for scene in scenes:
        if not scene.get("image_b64"):
            continue
        img_bytes = b64_to_bytes(scene["image_b64"])
        img = Image.open(io.BytesIO(img_bytes)).convert("RGB")
        images.append(img)

    if not images:
        return None, "NO_IMAGES"

    frames_per_scene = max(1, int(seconds_per_scene * fps))
    output_path = "imageking_output.mp4"

    try:
        writer = imageio.get_writer(output_path, fps=fps)  # imageio-ffmpeg í•„ìš”
    except Exception as e:
        return None, f"WRITER_ERROR: {e}"

    try:
        for img in images:
            frame = np.asarray(img)   # â† ì—¬ê¸° ìˆ˜ì • (imageio.asarray â†’ numpy.asarray)
            for _ in range(frames_per_scene):
                writer.append_data(frame)
        writer.close()
    except Exception as e:
        return None, f"WRITE_FRAME_ERROR: {e}"

    try:
        with open(output_path, "rb") as f:
            return f.read(), None
    except Exception as e:
        return None, f"FILE_READ_ERROR: {e}"

# =========================
# ì‚¬ì´ë“œë°”
# =========================
with st.sidebar:
    st.markdown("### ğŸ¬ IASA")
    st.markdown("---")

    st.markdown("#### ğŸ–¼ ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸")
    st.session_state["image_model_label"] = st.selectbox(
        "ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸",
        list(IMAGE_MODELS.keys()),
        index=list(IMAGE_MODELS.keys()).index(
            st.session_state.get("image_model_label", "OpenAI gpt-image-1")
        ),
    )

    st.markdown("#### ğŸ¨ ìŠ¤íƒ€ì¼ í”„ë¦¬ì…‹")
    st.session_state["style_preset"] = st.selectbox(
        "ìŠ¤íƒ€ì¼ ì„ íƒ",
        list(STYLE_PRESETS.keys()),
        index=list(STYLE_PRESETS.keys()).index(
            st.session_state.get("style_preset", "ë‹¤í + ìŠ¤í‹±ë§¨ ì„¤ëª… ìºë¦­í„°")
        ),
    )

    st.markdown("#### ğŸ§ ìºë¦­í„° ê³ ì •")
    st.session_state["lock_character"] = st.checkbox(
        "2D ìŠ¤í‹±ë§¨ ì„¤ëª… ìºë¦­í„° í•­ìƒ í¬í•¨",
        value=st.session_state.get("lock_character", True),
    )

    # === ì´ë¯¸ì§€ ì˜µì…˜: disclosure ê·¸ë£¹ ===
    with st.expander("ğŸ–¼ ì´ë¯¸ì§€ ì˜µì…˜", expanded=True):
        st.session_state["image_orientation"] = st.radio(
            "ë¹„ìœ¨ ì„ íƒ",
            ["ì •ì‚¬ê°í˜• 1:1 (1024x1024)", "ê°€ë¡œí˜• 3:2 (1536x1024)", "ì„¸ë¡œí˜• 2:3 (1024x1536)"],
            index=["ì •ì‚¬ê°í˜• 1:1 (1024x1024)", "ê°€ë¡œí˜• 3:2 (1536x1024)", "ì„¸ë¡œí˜• 2:3 (1024x1536)"].index(
                st.session_state.get("image_orientation", "ì •ì‚¬ê°í˜• 1:1 (1024x1024)")
            ),
        )

        st.session_state["image_quality"] = st.radio(
            "í’ˆì§ˆ",
            ["low", "high"],
            index=["low", "high"].index(st.session_state.get("image_quality", "low")),
            horizontal=True,
        )

    # === ì˜ìƒ ìƒì„± ì˜µì…˜: disclosure ê·¸ë£¹ ===
    with st.expander("ğŸ¥ ì˜ìƒ ìƒì„± ì˜µì…˜", expanded=True):
        st.session_state["video_model_label"] = st.selectbox(
            "ì˜ìƒ ìƒì„± ëª¨ë¸",
            list(VIDEO_MODELS.keys()),
            index=list(VIDEO_MODELS.keys()).index(
                st.session_state.get("video_model_label", "ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ â†’ MP4 (ë¡œì»¬ í•©ì„±)")
            ),
        )

        st.session_state["seconds_per_scene"] = st.slider(
            "ì¥ë©´ë‹¹ ì˜ìƒ ê¸¸ì´ (ì´ˆ)",
            min_value=1.0,
            max_value=10.0,
            value=float(st.session_state.get("seconds_per_scene", 3.0)),
            step=0.5,
        )

# =========================
# ë©”ì¸ UI
# =========================
st.markdown(
    """
    <div>
        <div class="logo-badge">
            <span class="emoji">ğŸ¬</span>
            <span>IASA</span>
        </div>
        <div class="main-title">imageking</div>
        <div class="main-subtitle">
            ëŒ€ë³¸ì„ ì…ë ¥í•˜ê³ , ë¬¸ì¥ë³„ í”„ë¡¬í”„íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ë²Œí¬ë¡œ ìƒì„±í•œ ë’¤,
            ì¥ë©´ë“¤ì„ ì´ì–´ë¶™ì—¬ ì˜ìƒê¹Œì§€ ìë™ìœ¼ë¡œ ë§Œë“¤ì–´ë³´ì„¸ìš”.
        </div>
    </div>
    """,
    unsafe_allow_html=True,
)

raw_text = st.text_area(
    "ì—¬ê¸°ì— ëŒ€ë³¸ì„ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.",
    height=260,
    value=st.session_state.get("raw_script", ""),
    placeholder="1\ní•œêµ­ì–´ ë¬¸ì¥â€¦ Shot on ...\n\n2\ní•œêµ­ì–´ ë¬¸ì¥â€¦ Shot on ...",
)

col_btn1, col_btn2 = st.columns(2)
with col_btn1:
    clicked_generate = st.button("ì´ë¯¸ì§€ ìƒì„±", type="primary", use_container_width=True)
with col_btn2:
    clicked_video = st.button("ì˜ìƒ ìƒì„±", type="secondary", use_container_width=True)

# =========================
# ì´ë¯¸ì§€ ìƒì„± ë²„íŠ¼ ë™ì‘
# =========================
if clicked_generate:
    if not raw_text.strip():
        st.warning("ëŒ€ë³¸ì„ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        scenes = parse_script(raw_text)
        if not scenes:
            st.error("ëŒ€ë³¸ í˜•ì‹ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë²ˆí˜¸ì™€ ë¬¸ì¥ í˜•ì‹ì„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
        else:
            st.session_state["raw_script"] = raw_text
            st.session_state["scenes"] = scenes

            with st.spinner("ì´ë¯¸ì§€ë¥¼ ë²Œí¬ë¡œ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                bulk_generate_images(st.session_state["scenes"], max_workers=4)

            st.success("âœ… ëŒ€ë³¸ì´ ìë™ìœ¼ë¡œ ë¶„ë¥˜ë˜ê³  ì´ë¯¸ì§€ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.session_state["video_bytes"] = None
            st.session_state["video_error_msg"] = None

scenes = st.session_state.get("scenes", [])

# =========================
# ì˜ìƒ ìƒì„± ë²„íŠ¼ ë™ì‘
# =========================
if clicked_video:
    if not scenes or not any(s.get("image_b64") for s in scenes):
        st.warning("ë¨¼ì € ì´ë¯¸ì§€ë¥¼ ìƒì„±í•œ í›„ì— ì˜ìƒì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        if imageio is None:
            st.session_state["video_error_msg"] = (
                "`imageio` ëª¨ë“ˆì´ ì—†ìŠµë‹ˆë‹¤. requirements.txt ì— `imageio` ì™€ `imageio-ffmpeg` ë¥¼ ì¶”ê°€í•œ ë’¤ ë‹¤ì‹œ ë°°í¬í•´ì£¼ì„¸ìš”."
            )
            st.session_state["video_bytes"] = None
        else:
            video_model_label = st.session_state.get("video_model_label", "ì´ë¯¸ì§€ ì‹œí€€ìŠ¤ â†’ MP4 (ë¡œì»¬ í•©ì„±)")
            video_model = VIDEO_MODELS.get(video_model_label, "local_sequence_mp4")

            if video_model == "local_sequence_mp4":
                seconds_per_scene = float(st.session_state.get("seconds_per_scene", 3.0))
                with st.spinner("ì˜ìƒì„ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                    video_bytes, err_msg = create_video_from_scenes(
                        scenes,
                        seconds_per_scene=seconds_per_scene,
                        fps=30,
                    )
                if video_bytes:
                    st.session_state["video_bytes"] = video_bytes
                    st.session_state["video_error_msg"] = None
                    st.success("ğŸ¬ ì˜ìƒì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
                else:
                    st.session_state["video_bytes"] = None
                    st.session_state["video_error_msg"] = (
                        "ì˜ìƒ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\n"
                        "ëŒ€ë¶€ë¶„ì€ `imageio-ffmpeg` ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ffmpeg í”ŒëŸ¬ê·¸ì¸ì„ ì°¾ì§€ ëª»í•´ì„œ ìƒê¸°ëŠ” ë¬¸ì œì…ë‹ˆë‹¤.\n"
                        "requirements.txt ì— `imageio-ffmpeg` ë¥¼ ì¶”ê°€í•˜ê³  ë‹¤ì‹œ ë°°í¬í•´ ì£¼ì„¸ìš”.\n\n"
                        f"ë‚´ë¶€ ì˜¤ë¥˜ ë©”ì‹œì§€: {err_msg}"
                    )
            else:
                st.session_state["video_error_msg"] = "ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì€ ì˜ìƒ ìƒì„± ëª¨ë¸ì…ë‹ˆë‹¤."
                st.session_state["video_bytes"] = None

# ==========================
# ê²°ê³¼ í…Œì´ë¸” (ìŠ¤í¬ë¡¤ ì»¨í…Œì´ë„ˆ)
# =========================
if scenes:
    st.subheader("ë¬¸ì¥ë³„ í”„ë¡¬í”„íŠ¸ ë° ì´ë¯¸ì§€")

    with st.container():
        st.markdown('<div class="results-container">', unsafe_allow_html=True)

        header_cols = st.columns([0.5, 2, 2, 1, 0.9])
        header_cols[0].markdown("**ë²ˆí˜¸**")
        header_cols[1].markdown("**ì›ë³¸ë¬¸ì¥**")
        header_cols[2].markdown("**ìƒì„±ëœ ì˜ì–´ í”„ë¡¬í”„íŠ¸**")
        header_cols[3].markdown("**ì´ë¯¸ì§€**")
        header_cols[4].markdown("**ì¡°ì‘**")

        st.markdown("---")

        for i, scene in enumerate(scenes):
            cols = st.columns([0.5, 2, 2, 1, 0.9])

            cols[0].write(scene["id"])

            korean_html = scene["korean"].replace("\n", "<br>")
            cols[1].markdown(
                f'<div class="small-text-cell">{korean_html}</div>',
                unsafe_allow_html=True,
            )

            prompt_html = scene["prompt_en"].replace("\n", "<br>")
            cols[2].markdown(
                f'<div class="small-text-cell">{prompt_html}</div>',
                unsafe_allow_html=True,
            )

            if scene["image_b64"]:
                img_bytes = b64_to_bytes(scene["image_b64"])
                cols[3].image(img_bytes, use_column_width=True)
            else:
                cols[3].write("ì•„ì§ ì´ë¯¸ì§€ ì—†ìŒ")

            if cols[4].button("ì¬ ìƒì„±", key=f"regen_{scene['id']}"):
                with st.spinner(f"{scene['id']}ë²ˆ ì´ë¯¸ì§€ë¥¼ ë‹¤ì‹œ ìƒì„± ì¤‘..."):
                    new_b64 = generate_image(scene["prompt_en"])
                    st.session_state["scenes"][i]["image_b64"] = new_b64
                st.rerun()

        st.markdown("</div>", unsafe_allow_html=True)
else:
    st.info("ëŒ€ë³¸ì„ ì…ë ¥í•˜ê³  **ì´ë¯¸ì§€ ìƒì„±** ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

# =========================
# ìƒì„±ëœ ì˜ìƒ / ì˜¤ë¥˜ í‘œì‹œ
# =========================
if st.session_state.get("video_bytes"):
    st.subheader("ğŸ¬ ìƒì„±ëœ ì˜ìƒ ë¯¸ë¦¬ë³´ê¸°")
    st.video(st.session_state["video_bytes"])

    st.download_button(
        label="ğŸ“¥ ì˜ìƒ ë‹¤ìš´ë¡œë“œ (MP4)",
        data=st.session_state["video_bytes"],
        file_name="imageking_output.mp4",
        mime="video/mp4",
    )
elif st.session_state.get("video_error_msg"):
    st.subheader("âš ï¸ ì˜ìƒ ìƒì„± ì˜¤ë¥˜")
    st.error(st.session_state["video_error_msg"])
